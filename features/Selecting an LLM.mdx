---
title: Selecting an LLM
description: 'Choose the right AI model for your Playlab project'
---

<div className="bg-blue-500 text-white px-6 py-4 rounded-lg mb-6 shadow-lg">
  <div className="flex items-center">
    <Icon icon="" size="2" className="mr-3 text-yellow-300" />
    <span className="font-semibold">ðŸŽ‰ NEW: <code className="bg-white/20 px-2 py-1 rounded text-sm">GPT-5</code>, <code className="bg-white/20 px-2 py-1 rounded text-sm">GPT-5 Mini</code>, and <code className="bg-white/20 px-2 py-1 rounded text-sm">GPT-5 Nano</code> are now available in Playlab!</span>
  </div>
</div>

<Note>
**New Models Added Regularly!** We're constantly adding and updating models to give Playlabbers access to the latest AI capabilities. Our goal is to provide more open weight models and eventually open source models to give you maximum flexibility and control over your applications.
</Note>
## <Icon icon="bell-on" size="24" className="inline-block align-text-bottom" /> What is this feature?

You can now build on top of even more LLMs in Playlab! There are now over 20 available AI models for you to build your Playlab apps on top of. We will try our best to always provide the latest models for you to build on top of.

<Warning>
  Changing the LLM may impact the performance of your app.
</Warning>

## <Icon icon="lightbulb" size="24" className="inline-block align-text-bottom" /> Rationale for the feature

This feature allows Playlab users to experiment with and leverage the unique strengths of various AI models from different providers all within Playlab.

As you build, you might find that certain models perform better at different tasks. This will allow Playlab users to select the model that fits their needs better. The more available models, the more likely you are to find one that meets your needs. We believe that Playlabbers should have access to frontier models as we build in community.

## <Icon icon="thought-bubble" size="24" className="inline-block align-text-bottom" /> Understanding Model Types

Before selecting a model, it's helpful to understand the different categories of AI models available:

| **Frontier Models** | **Open Weight Models** | **Open Source Models** |
|---|---|---|
| Cutting-edge, proprietary models developed by major AI companies | Models with publicly available parameters (weights) that can be downloaded and run independently | Fully open models where both weights and training code are publicly available |
| Typically offer the most advanced capabilities and are continuously updated with the latest research breakthroughs | While training code may not be available, you have more control over deployment and customization | Offer maximum transparency and customization potential |
| Examples: Claude 4 models, GPT-5 series, GPT-4 series, Gemini models | Examples: Llama models, DeepSeek R1, GPT OSS models, Kimi K2 | Coming soon! |

## <Icon icon="thought-bubble" size="24" className="inline-block align-text-bottom" /> How do I access these models?

<Steps>
  <Step title="Click the LLM selector">
    On the top left click the LLM. (By default it will be Claude 4 Sonnet)
    
    <img height="500" src="/images/Selectinganllm.gif" className="border border-gray-300 rounded-md shadow-sm" />
  </Step>
  <Step title="Choose your model">
    From the menu, select which LLM you want to build on top of. You can read more about available models below in greater detail.
  </Step>
    <Step title="Build and Test">
    See how the model you chose impacts your app. Continue trying out different models to find the "best" fit for your app.
  </Step>
</Steps>

## <Icon icon="list-check" size="24" className="inline-block align-text-bottom" /> Which models should I use?

Now that you know how to select models, here are some strengths and tradeoffs of each:

<CardGroup cols={2}>
  <Card title="Claude 3 Opus (Anthropic)" icon="sparkles">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Advanced model which can handle complex analysis, longer tasks with many steps, and higher-order math and coding.</p>
    <p><strong>âž• Strengths:</strong> Accuracy and strong at following detailed step by step instructions</p>
    <p><strong>âž– Trade Offs:</strong> Slower and may be overkill for simple, straightforward tasks. Superseded by Claude 4 Opus for most use cases.</p>
  </Card>

  <Card title="Claude 3.5 Haiku (Anthropic)" icon="leaf">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Designed for brevity and impactful language, focusing on concise and powerful text generation.</p>
    <p><strong>âž• Strengths:</strong> Fast response times and excellent for concise, clear communication. Good for simple tasks requiring clarity.</p>
    <p><strong>âž– Trade Offs:</strong> Less powerful than larger models. May struggle with complex, multi-step problems requiring detailed analysis.</p>
  </Card>

  <Card title="Claude 3.7 Sonnet (Anthropic)" icon="music">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> General purpose model balanced between speed and accuracy with an emphasis on expression and creativity.</p>
    <p><strong>âž• Strengths:</strong> Improved accuracy and instruction following capabilities. Good speed to performance ratio.</p>
    <p><strong>âž– Trade Offs:</strong> Not optimized for reasoning tasks. Not as fast as smaller models like Flash or GPT-4o. Superseded by Claude 4 Sonnet.</p>
  </Card>

  <Card title="Claude 4 Opus (Anthropic)" icon="crown">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Latest version of Claude Opus series. Advanced model for complex analysis, even longer tasks with many steps, and higher-order math and coding.</p>
    <p><strong>âž• Strengths:</strong> Exceptional performance on complex multi-step problems. Superior accuracy and reasoning depth. Best for critical applications requiring highest quality output.</p>
    <p><strong>âž– Trade Offs:</strong> Slower response times and higher cost. May be unnecessary for straightforward tasks.</p>
  </Card>

  <Card title="Claude 4 Sonnet (Anthropic)" icon="star">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Latest version of Claude Sonnet series. High-performance model balanced between speed and accuracy.</p>
    <p><strong>âž• Strengths:</strong> Excellent balance of speed and intelligence. Superior instruction following. Strong at both creative and analytical tasks. Efficient for a wide variety of tasks</p>
    <p><strong>âž– Trade Offs:</strong> More expensive than smaller models. May be overkill for very simple tasks.</p>
  </Card>

  <Card title="Claude 4 Sonnet (Reasoning) (Anthropic)" icon="brain">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Work through difficult problems using careful, step-by-step reasoning.</p>
    <p><strong>âž• Strengths:</strong> Exceptional step by step reasoning capabilities. Stronger at math and coding. Very good at explaining thought process</p>
    <p><strong>âž– Trade Offs:</strong> Slower response times. Not as optimized for creative tasks. Consider Claude 4 Sonnet or Claude 4 Opus for better overall performance.</p>
  </Card>

  <Card title="DeepSeek R1 (DeepSeek)" icon="water">
    <div className="text-xs bg-green-100 px-2 py-1 rounded mb-2 inline-block">Open Weight Model</div>
    <p><strong>Description:</strong> Open-source model designed for efficiency.</p>
    <p><strong>âž• Strengths:</strong> Cost-effective and efficient. Good for applications where budget is a primary concern. Open-source flexibility.</p>
    <p><strong>âž– Trade Offs:</strong> May not match performance of frontier models on complex tasks. Limited compared to more advanced models.</p>
  </Card>

  <Card title="Gemini 2.5 Flash (Google)" icon="bolt">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> General purpose model optimized for fast response times.</p>
    <p><strong>âž• Strengths:</strong> Extremely fast response times. Good for simple instruction following and high volume tasks</p>
    <p><strong>âž– Trade Offs:</strong> Not ideal for multi-step problem solving or complex instruction following. May miss nuance in instructions</p>
  </Card>

  <Card title="Gemini 2.5 Pro (Google)" icon="crown">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Google's most powerful thinking model with maximum response accuracy and state-of-the-art performance</p>
    <p><strong>âž• Strengths:</strong> Exceptional reasoning capabilities. High accuracy on complex tasks. Advanced problem-solving abilities.</p>
    <p><strong>âž– Trade Offs:</strong> Slower response times. Higher computational cost. May be overkill for simple tasks.</p>
  </Card>

  <Card title="GPT-4.1 (OpenAI)" icon="circle-o">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Good for complex tasks and problem solving across domains, especially technical tasks like coding.</p>
    <p><strong>âž• Strengths:</strong> Strong technical capabilities. Excellent for coding tasks. Versatile across multiple domains. Good instruction following.</p>
    <p><strong>âž– Trade Offs:</strong> Can be slower than lighter models. Sometimes overengineers simple solutions.</p>
  </Card>

  <Card title="GPT-4.1 Nano (OpenAI)" icon="circle">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> A faster, more cost-effective version of GPT-4.1.</p>
    <p><strong>âž• Strengths:</strong> Improved speed over GPT-4.1. Cost-effective for high-volume applications. Maintains good performance on most tasks.</p>
    <p><strong>âž– Trade Offs:</strong> Some reduction in capabilities compared to full GPT-4.1. May struggle with the most complex reasoning tasks.</p>
  </Card>

  <Card title="GPT-5 (OpenAI)" icon="circle-star">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> OpenAI's latest flagship model with breakthrough capabilities in reasoning, creativity, and multimodal understanding.</p>
    <p><strong>âž• Strengths:</strong> State-of-the-art performance across all domains. Exceptional reasoning and problem-solving. Advanced creative capabilities. Superior instruction following and nuance understanding.</p>
    <p><strong>âž– Trade Offs:</strong> Slower response times and higher cost. May be unnecessary for simple tasks. Premium pricing for cutting-edge capabilities.</p>
  </Card>

  <Card title="GPT-5 Mini (OpenAI)" icon="circle-star">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> A balanced version of GPT-5 optimized for everyday use with improved speed and efficiency.</p>
    <p><strong>âž• Strengths:</strong> Excellent balance of GPT-5 capabilities with faster response times. Cost-effective for regular applications. Strong performance across most tasks without premium overhead.</p>
    <p><strong>âž– Trade Offs:</strong> Slightly reduced capabilities compared to full GPT-5. May not excel at the most complex reasoning challenges requiring maximum model capacity.</p>
  </Card>

  <Card title="GPT-5 Nano (OpenAI)" icon="circle-star">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> The most efficient version of GPT-5, designed for high-volume applications and rapid responses.</p>
    <p><strong>âž• Strengths:</strong> Fastest response times in the GPT-5 family. Most cost-effective for high-volume usage. Still maintains core GPT-5 improvements over previous generations.</p>
    <p><strong>âž– Trade Offs:</strong> Limited capabilities compared to GPT-5 and GPT-5 Mini. Best suited for straightforward tasks rather than complex reasoning or creative work.</p>
  </Card>

  <Card title="GPT OSS 120B (OpenAI)" icon="circle">
    <div className="text-xs bg-green-100 px-2 py-1 rounded mb-2 inline-block">Open Weight Model</div>
    <p><strong>Description:</strong> OpenAI's large open weight model.</p>
    <p><strong>âž• Strengths:</strong> Open weights allow for customization and local deployment. Strong general capabilities. Good for research and experimentation.</p>
    <p><strong>âž– Trade Offs:</strong> Requires significant computational resources. May not match latest frontier model performance.</p>
  </Card>

  <Card title="GPT OSS 20B (OpenAI)" icon="circle">
    <div className="text-xs bg-green-100 px-2 py-1 rounded mb-2 inline-block">Open Weight Model</div>
    <p><strong>Description:</strong> OpenAI's medium open weight model.</p>
    <p><strong>âž• Strengths:</strong> More efficient than 120B version. Open weights for flexibility. Good balance of performance and resource requirements.</p>
    <p><strong>âž– Trade Offs:</strong> Lower capabilities than larger models. May struggle with complex reasoning tasks.</p>
  </Card>

  <Card title="GPT-4o (OpenAI)" icon="circle-o">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Advanced model with strong general knowledge and creative flair.</p>
    <p><strong>âž• Strengths:</strong> Well balanced and strong at following instructions. Good speed. Versatile and effective in many domains. Creative capabilities.</p>
    <p><strong>âž– Trade Offs:</strong> Falls in the middle in terms of response time. Sometimes overcomplicates simple tasks</p>
  </Card>

  <Card title="Kimi K2 (Moonshot)" icon="rocket">
    <div className="text-xs bg-green-100 px-2 py-1 rounded mb-2 inline-block">Open Weight Model</div>
    <p><strong>Description:</strong> Advanced open weight model that excels in using tools</p>
    <p><strong>âž• Strengths:</strong> Excellent tool usage capabilities. Good for applications requiring API integrations. Strong technical reasoning.</p>
    <p><strong>âž– Trade Offs:</strong> May be specialized for tool use rather than general conversation. Performance varies on creative tasks.</p>
  </Card>

  <Card title="Llama 3.3 70B Instruct (Meta)" icon="meta">
    <div className="text-xs bg-green-100 px-2 py-1 rounded mb-2 inline-block">Open Weight Model</div>
    <p><strong>Description:</strong> Advanced model for reasoning, math, and general knowledge.</p>
    <p><strong>âž• Strengths:</strong> Strong general well balanced use cases. Performs well in math. Effective at following clear instructions. Open weight flexibility.</p>
    <p><strong>âž– Trade Offs:</strong> Slower than smaller models. Does not follow instructions as well as Claude/GPT models.</p>
  </Card>

  <Card title="Llama 4 Maverick (Meta)" icon="meta">
    <div className="text-xs bg-green-100 px-2 py-1 rounded mb-2 inline-block">Open Weight Model</div>
    <p><strong>Description:</strong> Advanced open-weight model for reasoning, math, and general knowledge.</p>
    <p><strong>âž• Strengths:</strong> Improved reasoning capabilities over Llama 3.3. Strong performance in general knowledge tasks. Open weight benefits.</p>
    <p><strong>âž– Trade Offs:</strong> Not as fast as smaller models. May require more specific prompting for best results.</p>
  </Card>
  
  <Card title="Llama 4 Scout (Meta)" icon="meta">
    <div className="text-xs bg-green-100 px-2 py-1 rounded mb-2 inline-block">Open Weight Model</div>
    <p><strong>Description:</strong> Powerful for multi-document analysis, cross-lingual understanding, and context-aware reasoning.</p>
    <p><strong>âž• Strengths:</strong> Excellent at analyzing multiple documents simultaneously. Strong cross-lingual capabilities. Advanced contextual understanding.</p>
    <p><strong>âž– Trade Offs:</strong> May be slower for simple tasks. Specialized for document analysis rather than general usage.</p>
  </Card>

  <Card title="o3 Mini (OpenAI)" icon="brain-circuit">
    <div className="text-xs bg-blue-100 px-2 py-1 rounded mb-2 inline-block">Frontier Model</div>
    <p><strong>Description:</strong> Advanced model with multistep reasoning and complex problem-solving.</p>
    <p><strong>âž• Strengths:</strong> Excellent multi-step reasoning capabilities. Strong at following detailed analytical instructions. High accuracy with complex tasks</p>
    <p><strong>âž– Trade Offs:</strong> Noticeable slowdown versus other models. May be unnecessarily powerful for simple tasks. Not optimized for creative tasks.</p>
  </Card>
</CardGroup>

## <Icon icon="ballot-check" size="24" className="inline-block align-text-bottom" /> Tips for Selecting the Right Model

Selecting can be tricky. That's why we encourage you to play and experiment as you build to find the model that is best fit for your context.

### <Icon icon="scale-balanced" size="24" className="inline-block align-text-bottom" /> Selection Considerations

<Accordion title="Ask yourself what is an ideal response time for your app?">
  This will allow you to pick larger or smaller models that meet those needs. Claude 4 Sonnet and GPT-5 Mini offer excellent balance, while Claude 4 Opus and GPT-5 prioritize quality over speed. Gemini 2.5 Flash and GPT-5 Nano excel at speed for simple tasks.
</Accordion>

<Accordion title="Identify what complexity level is your task?">
  * For simple Q&A or content generation, lighter models like Gemini 2.5 Flash, Claude 3.5 Haiku, or GPT-5 Nano may suffice
  * For balanced everyday tasks, Claude 4 Sonnet, GPT-5 Mini, or GPT-4o are ideal
  * For the most complex multi-step reasoning, choose GPT-5, Claude 4 Opus, o3 Mini, Gemini 2.5 Pro, or reasoning-focused models
</Accordion>

<Accordion title="What is the level of accuracy you are requiring of your app?">
  * Critical accuracy use cases like data analysis, or HR operations might require GPT-5, Claude 4 Opus, Gemini 2.5 Pro, or other powerful models even if they're slower.
  * Use cases that require creativity or open ended responses work well with GPT-5, GPT-5 Mini, Claude 4 Sonnet, GPT-4o, or creative-focused models.
</Accordion>

<Accordion title="Do you need open weights or source code access?">
  * If you need model customization, local deployment, or transparency, consider open weight models like Llama 4 series, DeepSeek R1, or GPT OSS models
  * For maximum performance and latest capabilities, frontier models like GPT-5 series, Claude 4 series, GPT-4.1, or Gemini 2.5 series are typically best
  * Consider your long-term deployment and customization needs when choosing between proprietary and open models
</Accordion>

### <Icon icon="medal" size="24" className="inline-block align-text-bottom" /> Best Practices

<Accordion title="Try to match your model with your use case:">
  * **Everyday applications** â€“ Claude 4 Sonnet, GPT-5 Mini, or GPT-4o provide the best balance of performance and efficiency
  * **Critical/Complex applications** â€“ GPT-5, Claude 4 Opus, Gemini 2.5 Pro, or o3 Mini for highest accuracy and reasoning capability
  * **Creative applications** â€“ GPT-5, GPT-5 Mini, Claude 4 Sonnet, GPT-4o, or GPT-4.1 for creative tasks
  * **Problem-solving tools** â€“ GPT-5, Claude 4 Opus, o3 Mini, Gemini 2.5 Pro, or Llama 4 Maverick
  * **Document analysis** â€“ Claude 4 Opus or Llama 4 Scout for multi-document or cross-lingual analysis
  * **Technical/Coding tasks** â€“ GPT-5, GPT-4.1, Claude 4 Opus, or Kimi K2 for tool usage
  * **Educational explanation** â€“ GPT-5 Mini, Claude 4 Sonnet, Llama 3.3 70B Instruct, Llama 4 Maverick, or those with strong explanatory capabilities
  * **High-volume applications** â€“ Balance quality with speed using GPT-5 Nano, Claude 4 Sonnet, Gemini 2.5 Flash, or GPT-4.1 Nano
  * **Budget-conscious applications** â€“ GPT-5 Nano, DeepSeek R1 or open weight models for cost-effective solutions
  * **Research/Experimentation** â€“ Open weight models like Llama 4 series or GPT OSS models for flexibility
</Accordion>

<Accordion title="Test out multiple models for apps that you are building:">
  * Changing a model may change performance of an app in Playlab
  * Test multiple models before finalizing â€“ Performance can vary significantly on your specific tasks
  * Implement A/B testing as you're building and testing to continually evaluate model performance
  * Consider starting with Claude 4 Sonnet or GPT-5 Mini as your baseline for most applications
  * Test both frontier and open weight models to find the best fit for your needs
</Accordion>

<Accordion title="Additional best practices:">
  * We recommend that you remix apps as you're experimenting to not impact the original app
  * You can review activity to see how multiple models handle similar tasks  
  * If you're building a suite of apps we recommend you use faster models for simple queries and reserve powerful models like GPT-5, Claude 4 Opus or Gemini 2.5 Pro for complex tasks
  * Consider cost implications - newer frontier models like GPT-5 may be more expensive but offer better performance
  * For production apps requiring customization, evaluate open weight models alongside frontier options
  * Keep track of which models work best for your specific use cases to build your own selection guidelines
</Accordion>

## <Icon icon="circle-question" size="24" className="inline-block align-text-bottom" /> FAQ

<Accordion title="Will switching models affect my existing app?">
  Yes, changing the LLM model can impact the performance of your app. Different models have different strengths and trade-offs, so it's important to test your app with the new model before finalizing the change.
</Accordion>

<Accordion title="How do I know which model is best for my specific use case?">
  We recommend experimenting with different models for your specific use case. Consider factors like response time requirements, complexity level of tasks, accuracy needs, and whether you need open weights. You can implement A/B testing to evaluate model performance. For most applications, Claude 4 Sonnet or GPT-5 Mini are great starting points.
</Accordion>

<Accordion title="Can I use different models for different parts of my app suite?">
  Yes! We recommend using faster models for simple queries and reserving more powerful models like GPT-5, Claude 4 Opus, Gemini 2.5 Pro, or o3 Mini for complex tasks if you're building a suite of apps.
</Accordion>

<Accordion title="When should I choose Claude 4 Sonnet vs Claude 4 Opus vs GPT-5?">
  Choose Claude 4 Sonnet for most everyday applications where you need a good balance of performance and efficiency. Choose Claude 4 Opus when you need the highest accuracy and reasoning capability for complex, critical tasks where performance is more important than speed. Choose GPT-5 when you need the absolute latest capabilities and breakthrough performance across all domains, especially for cutting-edge applications.
</Accordion>

<Accordion title="Should I upgrade from older Claude models?">
  Yes, Claude 4 Sonnet and Claude 4 Opus generally outperform their predecessors. Claude 4 Sonnet is recommended over Claude 3.5/3.7 Sonnet for most use cases, while Claude 4 Opus supersedes Claude 3 Opus for complex reasoning tasks.
</Accordion>

<Accordion title="What's the difference between GPT-5, GPT-5 Mini, and GPT-5 Nano?">
  GPT-5 offers the latest breakthrough capabilities with maximum performance but slower speeds and higher costs. GPT-5 Mini provides an excellent balance of GPT-5's improvements with faster response times and better cost efficiency. GPT-5 Nano is optimized for speed and high-volume applications while maintaining core improvements over previous generations.
</Accordion>

<Accordion title="What's the difference between frontier, open weight, and open source models?">
  Frontier models are cutting-edge proprietary models with the latest capabilities but require API access. Open weight models have publicly available parameters, allowing more control and customization. Open source models provide both weights and training code. Choose based on your needs for performance vs. customization and transparency.
</Accordion>

<Accordion title="When should I consider open weight models like Llama 4 or DeepSeek R1?">
  Consider open weight models when you need model customization, local deployment, cost control for high-volume applications, or transparency into model operations. They're also great for research and experimentation. However, frontier models typically offer better performance for most production applications.
</Accordion>

<Accordion title="How do I decide between GPT-4.1 and GPT-4.1 Nano?">
  Choose GPT-4.1 for complex technical tasks requiring maximum capability. Choose GPT-4.1 Nano for applications where speed and cost are more important than peak performance, especially for high-volume or simpler tasks.
</Accordion>

## <Icon icon="bullhorn" size="24" className="inline-block align-text-bottom" /> We Want Your Feedback!

<Info>
  Have you tried building with different LLM models? We'd love to hear about your experience with the new models and which ones work best for your use cases!

  Contact us at [support@playlab.ai](mailto:support@playlab.ai)
</Info>

<div className="mt-8">
  <Button href="../index.md">Return to Home Page</Button>
</div>

---
Last updated: 8/8/2025